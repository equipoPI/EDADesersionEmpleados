{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tengo este dataset y quiero responder estas preguntas con los algoritmos de skitlearn.\n",
    "Preguntas EDA\n",
    "Predicción:\n",
    "* 1- ¿Cuál es la probabilidad de que un empleado deje la empresa en función de su antigüedad, satisfacción laboral, oportunidades de liderazgo y balance trabajo-vida?\n",
    "* 2- ¿Cuál es el ingreso mensual esperado para un empleado nuevo en función de su nivel de educación, rol de trabajo, y tamaño de la empresa?\n",
    "* 3- ¿Cuál será el nivel de desempeño de un empleado en el próximo año en función de su nivel de trabajo, oportunidades de innovación, y horas extras?\n",
    "* 4- ¿Qué tan probable es que un empleado reciba una promoción en el siguiente año basándonos en sus años de antigüedad, nivel de desempeño, y número de dependientes?\n",
    "Clasificación:\n",
    "* 5-¿Qué puntuación de satisfacción laboral se puede asignar a un empleado considerando el balance trabajo-vida, la reputación de la empresa y las oportunidades de liderazgo?\n",
    "* 6- ¿Qué calificación de desempeño podemos esperar de un empleado con base en sus años de antigüedad, nivel de educación y número de promociones?\n",
    "* 7- ¿Cómo calificar la probabilidad de que un empleado reciba reconocimiento considerando su desempeño y el tamaño de la empresa?\n",
    "* 8- ¿Cuál sería la calificación de riesgo de deserción de un empleado considerando sus años de antigüedad, satisfacción laboral y oportunidades de innovación?\n",
    "Clustering:\n",
    "* 9- ¿Cómo se agrupan los empleados en función de su satisfacción laboral y balance trabajo-vida?\n",
    "* 10- ¿Qué grupos de empleados se pueden formar basándonos en el nivel de educación, desempeño y antigüedad en la empresa?\n",
    "\n",
    "los algoritmos que tengo para hacer esto son bosques aleatorios, regresión lineal, regresión logic, descenso del gradiente, descenso al gradiente en lote, descenso del gradiente estocastico, descenso al gradiente en mini lotes, regresion polinómica, regresion ridge, regresion lasso, elastic net, early stoping, regresion softmax, support vetor machines, linear svm clasification, nonlinear svm clasification, kernel polinomico, linear svm regresion, bayes ingenuos, k vecinos cercanos, arboles de decision, k-means, mean shift, clusterin jerarquico aglomerativo, dbscan, hdbscan, optics.\n",
    "\n",
    "\n",
    "Predicción (1-4): Para estas tareas de regresión, podemos emplear algoritmos como:\n",
    "\n",
    "Regresión lineal o regresión polinómica (si hay relaciones no lineales).\n",
    "Bosques aleatorios para captar relaciones complejas.\n",
    "Regresión Ridge, Lasso, Elastic Net para regularización y evitar el sobreajuste.\n",
    "\n",
    "Clasificación (5-8): Para estas tareas de clasificación, podemos utilizar:\n",
    "\n",
    "Logistic Regression (si es binaria) o Support Vector Machines (para calificaciones).\n",
    "K vecinos cercanos y bosques aleatorios para un enfoque no lineal.\n",
    "\n",
    "Clustering (9-10): Para identificar grupos de empleados, emplearemos:\n",
    "\n",
    "K-Means o clustering jerárquico aglomerativo para crear clusters.\n",
    "DBSCAN o HDBSCAN si queremos un enfoque basado en densidad, útil para datos distribuidos de forma no homogénea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 3- ¿Cuál será el nivel de desempeño de un empleado en el próximo año en función de su nivel de trabajo, oportunidades de innovación, y horas extras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de alpha: 0.0001\n",
      "Métricas en el conjunto de validación:\n",
      "R²: 0.0005773142842033785\n",
      "RMSE: 0.21593531969572352\n",
      "MAE: 0.1244691967235933\n",
      "\n",
      "Métricas en el conjunto de prueba:\n",
      "R²: 0.0015303833523956367\n",
      "RMSE: 0.21441689207298673\n",
      "MAE: 0.12421455334832905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Escuela\\Facultad\\2024\\Segundo Cuatrimestre\\Machine learning\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "d:\\Escuela\\Facultad\\2024\\Segundo Cuatrimestre\\Machine learning\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "archivo = 'archivo_estandarizado_normalizado.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Selección de las características (X) y la variable objetivo (Y)\n",
    "X = df[['Horas Extras+norm', 'Oportunidades de Innovación+norm', 'Nivel de Trabajo+norm']]\n",
    "Y = df['Desempeño+norm']\n",
    "\n",
    "# Divide el 80% para entrenamiento y 20% para validación/prueba\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Divide el 20% restante en partes iguales para validación y prueba (10% y 10%)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Búsqueda de hiperparámetros para el mejor valor de alpha\n",
    "alpha_range = [0.0001, 0.001, 0.01, 0.05, 0.1, 1, 10, 100]\n",
    "param_grid = {'alpha': alpha_range}\n",
    "lasso = Lasso(random_state=42)\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Mejor valor de alpha obtenido\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(\"Mejor valor de alpha:\", best_alpha)\n",
    "\n",
    "# Crear y ajustar el modelo Lasso con el mejor valor de alpha\n",
    "lasso_best = Lasso(alpha=best_alpha, random_state=42)\n",
    "lasso_best.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluación en el conjunto de validación\n",
    "validation_prediction = lasso_best.predict(X_val)\n",
    "r2_val = metrics.r2_score(Y_val, validation_prediction)\n",
    "rmse_val = metrics.mean_squared_error(Y_val, validation_prediction, squared=False)\n",
    "mae_val = metrics.mean_absolute_error(Y_val, validation_prediction)\n",
    "\n",
    "print('Métricas en el conjunto de validación:')\n",
    "print('R²:', r2_val)\n",
    "print('RMSE:', rmse_val)\n",
    "print('MAE:', mae_val)\n",
    "\n",
    "# Evaluación en el conjunto de prueba\n",
    "test_prediction = lasso_best.predict(X_test)\n",
    "r2_test = metrics.r2_score(Y_test, test_prediction)\n",
    "rmse_test = metrics.mean_squared_error(Y_test, test_prediction, squared=False)\n",
    "mae_test = metrics.mean_absolute_error(Y_test, test_prediction)\n",
    "\n",
    "print('\\nMétricas en el conjunto de prueba:')\n",
    "print('R²:', r2_test)\n",
    "print('RMSE:', rmse_test)\n",
    "print('MAE:', mae_test)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
